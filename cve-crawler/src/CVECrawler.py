import calendar
import datetime
import json
import logging
import os
import time
import requests
import xml.etree.ElementTree as ET


class CVECrawler:
    def __init__(self,
                 path_storage='/Users/dravalico/PycharmProjects/crawlers/cve-crawler/CVE',
                 request_timeout=10,
                 update_interval=21600,
                 retry_interval=3600):
        self.path_storage = path_storage
        self.request_timeout = request_timeout
        self.update_interval = update_interval
        self.retry_interval = retry_interval
        log_format = f'[%(levelname)s at %(asctime)s] %(message)s'
        logging.basicConfig(level=logging.INFO, format=log_format, datefmt="%Y-%m-%d %H:%M:%S")

    def run(self):
        if not os.path.exists(self.path_storage):
            os.makedirs(self.path_storage)
        while True:
            endpoint_cve = 'https://cveawg.mitre.org/api/cve/'
            for year in range(1999, int(datetime.date.today().year) + 1):
                published_cve = self.retrieve_published_cve_per_year(year)
                local_cve = self.retrieve_saved_cve_list(year)
                cve_to_download = set(published_cve) - set(local_cve)
                for cve in cve_to_download:
                    url = endpoint_cve + cve
                    try:
                        response = requests.get(url, timeout=self.request_timeout)
                        if response.status_code == 200:
                            response_json = response.json()
                            complete_json = self.add_references_to_json(response_json)
                            self.save_cve_data(complete_json)
                            logging.info(f'Data obtained for {url.split("/")[-1]}')
                        elif response.status_code == 404:
                            logging.error(f'{url.split("/")[-1]} does not exists, error {response.status_code}')
                        elif response.status_code == 429:
                            time.sleep(self.retry_interval)
                        else:
                            logging.warning(f'Cannot obtain data for {url.split("/")[-1]}')
                    except:
                        logging.exception(f'Error for {url.split("/")[-1]} during GET')
            time.sleep(self.update_interval)

    def retrieve_published_cve_per_year(self, year):
        xml_data = self.download_summary_per_year(year)
        published_cve = []
        for vulnerability_element in xml_data.findall(".//{http://www.icasi.org/CVRF/schema/vuln/1.1}Vulnerability"):
            notes = vulnerability_element.find("{http://www.icasi.org/CVRF/schema/vuln/1.1}Notes")
            is_published = any(
                note.get("Title") == 'Published' for note in
                notes.findall("{http://www.icasi.org/CVRF/schema/vuln/1.1}Note"))
            if is_published:
                cve = vulnerability_element.find("{http://www.icasi.org/CVRF/schema/vuln/1.1}CVE").text
                published_cve.append(cve)
        return published_cve

    def download_summary_per_year(self, year):
        summaries_path = 'cve_summaries_per_year'
        file_path = os.path.join(self.path_storage, summaries_path, f'{year}.xml')
        if not os.path.exists(os.path.dirname(file_path)):
            os.makedirs(os.path.dirname(file_path))
        try:
            return ET.parse(file_path).getroot()
        except (FileNotFoundError, ET.ParseError) as e:
            logging.info(f'Downloading summary of {year}')
            all_items_cvrf_endpoint = f'https://cve.mitre.org/data/downloads/allitems-cvrf-year-{year}.xml'
            response = requests.get(all_items_cvrf_endpoint, timeout=self.request_timeout + 15)
            if response.status_code == 200:
                with open(file_path, 'wb') as file:
                    file.write(response.content)
                return ET.fromstring(response.content)
            else:
                logging.error(f'Failed to download data for {year}. Status code: {response.status_code}')
                return []

    def retrieve_saved_cve_list(self, year):
        return []

    def save_cve_data(self, json_data):
        date = json_data['cveMetadata']['dateReserved']
        split_date = date.split('-')
        year = split_date[0]
        month = split_date[1]
        month_full = month + "-" + calendar.month_name[int(month.lstrip('0'))]
        day = split_date[2].split('T')[0]
        year_path = os.path.join(self.path_storage, year)
        if not os.path.exists(year_path):
            os.makedirs(year_path)
        month_path = os.path.join(year_path, month_full[:6])
        if not os.path.exists(month_path):
            os.makedirs(month_path)
        with open(os.path.join(month_path, f'{year}_{month}_{day}.jsonl'), 'a', encoding='utf-8') as file:
            file.write(json.dumps(json_data) + '\n')

    def add_references_to_json(self, json_data):
        references = []
        for ref in json_data['containers']['cna']['references']:
            references.append(ref['url'])
        read_references = []
        for ref_url in references:
            try:
                response = requests.get(ref_url, timeout=self.request_timeout)
                if response.status_code == 200:
                    read_references.append((ref_url, response.text))
                else:
                    read_references.append((ref_url, response.status_code))
            except:
                read_references.append((ref_url, "Error with the request"))
        json_data['added_references'] = read_references
        return json_data
