import logging
import os
import time
import requests


class ExploitDbCrawler:
    def __init__(self,
                 path_storage='/usr/src/data',
                 request_timeout=10,
                 update_interval=3600,
                 retry_interval=60):
        self.path_storage = path_storage
        self.request_timeout = request_timeout
        self.update_interval = update_interval
        self.retry_interval = retry_interval
        log_format = f'[%(levelname)s at %(asctime)s] %(message)s'
        logging.basicConfig(level=logging.INFO, format=log_format, datefmt="%Y-%m-%d %H:%M:%S")

    def run(self):
        if not os.path.exists(self.path_storage):
            os.makedirs(self.path_storage)
        while True:
            self.download_data(self.retrieve_last_edb_id())
            time.sleep(self.update_interval)

    def retrieve_last_edb_id(self):
        pass

    def download_data(self):
        endpoint_exploits = 'https://www.exploit-db.com/exploits/'
        pass
